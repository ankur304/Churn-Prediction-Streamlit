# -*- coding: utf-8 -*-
"""ANN Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1w8zsikkDdfaH452moUJod78SdEKEX8Xt
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
import pickle

# Load the dataset
data = pd.read_csv('/content/Churn_Modelling.csv')
data.head()

## Preprocess the data
# Drop irrelevant features
data = data.drop(['RowNumber','CustomerId','Surname'],axis = 1)
data.head()

## Encode categorical variables
label_encoder_gender =  LabelEncoder()
data['Gender'] = label_encoder_gender.fit_transform(data['Gender'])
data

## Onehot encoding Geography
from sklearn.preprocessing import OneHotEncoder
onehot_encoder_geo = OneHotEncoder()
geo_encoder = onehot_encoder_geo.fit_transform(data[['Geography']])
geo_encoder

onehot_encoder_geo.get_feature_names_out(['Geography'])

geo_encoder_df = pd.DataFrame(geo_encoder.toarray(),columns = onehot_encoder_geo.get_feature_names_out(['Geography']))
geo_encoder_df  # geo_encoder.toarray() need to given after converting into array

# Combine one hot encoder columns with the original data
data = pd.concat([data.drop('Geography', axis = 1),geo_encoder_df], axis = 1)
data

## save the encoder and scaler
with open('label_encoder_gender.pkl', 'wb') as file:
  pickle.dump(geo_encoder_df, file)

with open('onehot_encoder_geo.pkl', 'wb') as file:
  pickle.dump(onehot_encoder_geo, file)

## Divide the dataset
X = data.drop('Exited', axis = 1)
y = data['Exited']

# train test split
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 42)

# Standard scaler
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

with open('scaler.pkl','wb') as file:
  pickle.dump(scaler, file)

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.callbacks import EarlyStopping, TensorBoard
import datetime

## Build model
model = Sequential([
    Dense(64, activation='relu', input_shape = (X_train.shape[1],),kernel_regularizer=tf.keras.regularizers.l1(0.001)),  # first hidden layer connected with input layer
    Dense(32, activation = 'relu',kernel_regularizer=tf.keras.regularizers.l1(0.001) ),
    Dense(1, activation = 'sigmoid')
])

model.summary()

import tensorflow
opt = tensorflow.keras.optimizers.Adam(learning_rate = 0.01)

# Compile the model
model.compile(optimizer= opt,loss = 'binary_crossentropy',metrics = ['accuracy'])

## Set up the Tensorboard
log_dir = "logs/fit/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")

tensorflow_callback = TensorBoard(log_dir = log_dir,histogram_freq = 1)

## Set up early stopping
early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 5, restore_best_weights = True)

history = model.fit(
    X_train, y_train, validation_data = (X_test, y_test),
    epochs = 200, callbacks=[tensorflow_callback,early_stopping_callback]


)

model.save('model.h5')

# Commented out IPython magic to ensure Python compatibility.
## Load Tesorboard Extension
# %load_ext tensorboard

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir logs/fit

# Load the pickle file
from tensorflow.keras.models import load_model

# Load the pickle file, trained model, scaler, onehot
model = load_model('model.h5')

with open('onehot_encoder_geo.pkl', 'rb') as file:
  lable_encoder_geo = pickle.load(file)

with open('label_encoder_gender.pkl', 'rb') as file:
  label_encoder_gender = pickle.load(file)

with open('scaler.pkl', 'rb') as file:
  scaler = pickle.load(file)

# Example Input data
input_data = {
    'CreditScore': 600,
    'Geography': 'France',
    'Gender': 'Male',
    'Age': 40,
    'Tenure': 3,
    'Balance': 60000,
    'NumOfProducts': 2,
    'HasCrCard': 1,
    'IsActiveMember': 1,
    'EstimatedSalary': 50000
}

# One hot encoding 'Geography'
geo_encoded = lable_encoder_geo.transform([[input_data['Geography']]]).toarray() # double brackets are used
geo_encoded_df = pd.DataFrame(geo_encoded, columns = lable_encoder_geo.get_feature_names_out(['Geography']))
geo_encoded_df

input_df = pd.DataFrame([input_data])
input_df

input_df['Gender'] = label_encoder_gender.transform(input_df['Gender'])

input_df

## concatenation one hot encoded
input_df = pd.concat([input_df.drop('Geography', axis =1),geo_encoded_df], axis =1)

input_df

## Scaler the data
input_scaled = scaler.transform(input_df)
input_scaled

## Prediction
prediction = model.predict(input_scaled)
prediction

prediction_proba =  prediction[0][0]
prediction_proba

if prediction_proba > 0.5:
  print("Customer will churn")
else:
  print("Customer will not churn")
# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py

# app.py

import streamlit as st
import numpy as np
import pandas as pd
import tensorflow as tf
import pickle

# Load the trained model
model = tf.keras.models.load_model('model.h5')

# Load the encoders and scaler
with open('onehot_encoder_geo.pkl', 'rb') as file:
    onehot_encoder_geo = pickle.load(file)

with open('label_encoder_gender.pkl', 'rb') as file:
    label_encoder_gender = pickle.load(file)

with open('scaler.pkl', 'rb') as file:
    scaler = pickle.load(file)

# Streamlit UI
st.title('Customer Churn Prediction')

# User input
geography = st.selectbox('Geography', onehot_encoder_geo.categories_[0])
gender = st.selectbox('Gender', label_encoder_gender.classes_)
age = st.slider('Age', 18, 92)
balance = st.number_input('Balance')
credit_score = st.number_input("Credit Score")
estimated_salary = st.number_input('Estimated Salary')
tenure = st.slider('Tenure', 0, 10)
num_of_products = st.slider('Number of Products', 1, 4)
has_cr_card = st.selectbox('Has credit card', [0, 1])
is_active_member = st.selectbox('Is Active Member', [0, 1])

# Prepare input data
input_data = pd.DataFrame({
    'CreditScore': [credit_score],
    'Gender': [label_encoder_gender.transform([gender])[0]],
    'Age': [age],
    'Tenure': [tenure],
    'Balance': [balance],
    'NumOfProducts': [num_of_products],
    'HasCrCard': [has_cr_card],
    'IsActiveMember': [is_active_member],
    'EstimatedSalary': [estimated_salary]
})

# One-hot encode geography
geo_encoded = onehot_encoder_geo.transform([[geography]]).toarray()
geo_encoded_df = pd.DataFrame(geo_encoded, columns=onehot_encoder_geo.get_feature_names_out(['Geography']))

# Combine with input data
input_data = pd.concat([input_data.reset_index(drop=True), geo_encoded_df], axis=1)

# Scale the data
input_data_scaled = scaler.transform(input_data)

# Predict churn
prediction = model.predict(input_data_scaled)
prediction_proba = prediction[0][0]

# Display result
if prediction_proba > 0.5:
    st.error("The customer is likely to churn.")
else:
    st.success("The customer is not likely to churn.")

